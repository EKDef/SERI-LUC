{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Filter and create geoparquet file",
   "id": "f90590a633881df8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T13:42:45.743635Z",
     "start_time": "2025-05-15T13:42:41.027855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load inputs\n",
    "gdf = gpd.read_file(\"./msoa_2021.geojson\")    # your GeoJSON file\n",
    "df  = pd.read_csv(\"./msoa_attributes.csv\")        # your CSV with matching key\n",
    "\n",
    "# 2. Keep only the join key and geometry from the GeoJSON\n",
    "gdf = gdf[['MSOA21CD', 'geometry']]\n",
    "\n",
    "# 3. Remember original CRS\n",
    "orig_crs = gdf.crs\n",
    "\n",
    "# 4. Reproject to a metric CRS (units in metres) for simplification\n",
    "gdf = gdf.to_crs(epsg=3857)\n",
    "\n",
    "# 5. Simplify geometries to ~50 m tolerance\n",
    "gdf['geometry'] = gdf['geometry'].simplify(\n",
    "    tolerance=50,\n",
    "    preserve_topology=True\n",
    ")\n",
    "\n",
    "# 6. Reproject back to original CRS\n",
    "gdf = gdf.set_geometry('geometry').to_crs(orig_crs)\n",
    "\n",
    "# 7. Merge attributes from CSV on MSOA21CD\n",
    "gdf = gdf.merge(df, on='MSOA21CD', how='left')\n",
    "\n",
    "# 8. Filter out any MSOA21CD starting with 'W'\n",
    "gdf = gdf[~gdf['MSOA21CD'].str.startswith('W')]\n",
    "\n",
    "# 8. Filter out any MSOA21CD starting with 'S'\n",
    "gdf = gdf[~gdf['MSOA21CD'].str.startswith('S')]\n",
    "\n",
    "# 9. Write to GeoParquet\n",
    "gdf.to_parquet(\n",
    "    \"msoa_2021_data.parquet\",\n",
    "    engine=\"pyarrow\",\n",
    "    index=False\n",
    ")\n"
   ],
   "id": "1d372eb4ae18b03f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create LOD files",
   "id": "f53126e55c53fcc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:56:30.382418Z",
     "start_time": "2025-05-15T16:56:22.233584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def create_simplified_files(input_file, output_dir):\n",
    "    \"\"\"Create simplified versions of a geoparquet file.\"\"\"\n",
    "    # Load the original data\n",
    "    print(f\"Loading {input_file}...\")\n",
    "    gdf = gpd.read_parquet(input_file)\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save original (high detail)\n",
    "    original_path = output_dir / \"high_detail.parquet\"\n",
    "    print(f\"Saving high detail to {original_path}...\")\n",
    "    gdf.to_parquet(original_path)\n",
    "\n",
    "    # Create and save medium detail\n",
    "    medium_gdf = gdf.copy()\n",
    "    print(\"Creating medium detail...\")\n",
    "    medium_gdf['geometry'] = medium_gdf['geometry'].simplify(\n",
    "        tolerance=0.001, preserve_topology=True)\n",
    "    medium_path = output_dir / \"medium_detail.parquet\"\n",
    "    print(f\"Saving medium detail to {medium_path}...\")\n",
    "    medium_gdf.to_parquet(medium_path)\n",
    "\n",
    "    # Create and save low detail\n",
    "    low_gdf = gdf.copy()\n",
    "    print(\"Creating low detail...\")\n",
    "    low_gdf['geometry'] = low_gdf['geometry'].simplify(\n",
    "        tolerance=0.005, preserve_topology=True)\n",
    "    low_path = output_dir / \"low_detail.parquet\"\n",
    "    print(f\"Saving low detail to {low_path}...\")\n",
    "    low_gdf.to_parquet(low_path)\n",
    "\n",
    "    # Print statistics\n",
    "    orig_size = len(gdf.geometry.to_wkt().sum())\n",
    "    med_size = len(medium_gdf.geometry.to_wkt().sum())\n",
    "    low_size = len(low_gdf.geometry.to_wkt().sum())\n",
    "\n",
    "    print(f\"Original size: {orig_size:,}, Medium: {med_size:,}, Low: {low_size:,}\")\n",
    "    print(f\"Reduction - Medium: {(1-med_size/orig_size)*100:.1f}%, Low: {(1-low_size/orig_size)*100:.1f}%\")\n",
    "\n",
    "    return {\n",
    "        \"high\": str(original_path),\n",
    "        \"medium\": str(medium_path),\n",
    "        \"low\": str(low_path)\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = Path(\"./msoa_2021_data.parquet\")\n",
    "    output_dir = Path(\"./lod_versions\")\n",
    "    file_paths = create_simplified_files(input_file, output_dir)\n",
    "\n",
    "    # Print the resulting file paths\n",
    "    print(\"\\nGenerated files:\")\n",
    "    for level, path in file_paths.items():\n",
    "        print(f\"  {level}: {path}\")\n",
    "\n",
    "    print(\"\\nTo use these optimized files with the MSOA Explorer app:\")\n",
    "    print(\"1. Make sure the files are in the 'lod_versions' subdirectory\")\n",
    "    print(\"2. Launch the Streamlit app normally - it will detect and use the optimized files\")"
   ],
   "id": "edbd3bb0d77f5511",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading msoa_2021_data.parquet...\n",
      "Saving high detail to lod_versions\\high_detail.parquet...\n",
      "Creating medium detail...\n",
      "Saving medium detail to lod_versions\\medium_detail.parquet...\n",
      "Creating low detail...\n",
      "Saving low detail to lod_versions\\low_detail.parquet...\n",
      "Original size: 12,485,076, Medium: 5,797,155, Low: 1,757,769\n",
      "Reduction - Medium: 53.6%, Low: 85.9%\n",
      "\n",
      "Generated files:\n",
      "  high: lod_versions\\high_detail.parquet\n",
      "  medium: lod_versions\\medium_detail.parquet\n",
      "  low: lod_versions\\low_detail.parquet\n",
      "\n",
      "To use these optimized files with the MSOA Explorer app:\n",
      "1. Make sure the files are in the 'lod_versions' subdirectory\n",
      "2. Launch the Streamlit app normally - it will detect and use the optimized files\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T17:54:54.744807Z",
     "start_time": "2025-05-15T17:54:38.633991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "geojson_path = Path(\"./msoa_2021.geojson\")\n",
    "csv_dir = Path(\"./csv\")\n",
    "parquet_dir = Path(\"./parquet\")\n",
    "lod_dir = Path(\"./lod_versions\")\n",
    "\n",
    "# Ensure output directories exist\n",
    "parquet_dir.mkdir(parents=True, exist_ok=True)\n",
    "lod_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load base GeoJSON and keep only key + geometry\n",
    "gdf_base = gpd.read_file(geojson_path)[['MSOA21CD', 'geometry']]\n",
    "orig_crs = gdf_base.crs\n",
    "# Reproject to metric for simplification\n",
    "gdf_base = gdf_base.to_crs(epsg=3857)\n",
    "# Simplify geometries once at tolerance 50m\n",
    "gdf_base['geometry'] = gdf_base['geometry'].simplify(\n",
    "    tolerance=50,\n",
    "    preserve_topology=True\n",
    ")\n",
    "# Back to original CRS\n",
    "gdf_base = gdf_base.set_geometry('geometry').to_crs(orig_crs)\n",
    "\n",
    "# Iterate over each CSV in csv_dir\n",
    "def preprocess_csv(csv_file: Path):\n",
    "    # Read attributes\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # Merge with base geometries\n",
    "    gdf = gdf_base.merge(df, on='MSOA21CD', how='left')\n",
    "    # Filter out unwanted MSOAs\n",
    "    gdf = gdf[~gdf['MSOA21CD'].str.startswith(('W', 'S'))]\n",
    "\n",
    "    # Define output paths\n",
    "    stem = csv_file.stem  # e.g. 'msoa_attributes'\n",
    "    parquet_path = parquet_dir / f\"{stem}.parquet\"\n",
    "\n",
    "    # Save preprocessed parquet\n",
    "    gdf.to_parquet(parquet_path, engine='pyarrow', index=False)\n",
    "    print(f\"Saved preprocessed: {parquet_path}\")\n",
    "    return parquet_path\n",
    "\n",
    "# LOD creation function\n",
    "def create_lod_files(input_parquet: Path, output_subdir: Path):\n",
    "    gdf = gpd.read_parquet(input_parquet)\n",
    "    output_subdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # High detail\n",
    "    high_path = output_subdir / \"high_detail.parquet\"\n",
    "    gdf.to_parquet(high_path, engine='pyarrow', index=False)\n",
    "\n",
    "    # Medium detail\n",
    "    med = gdf.copy()\n",
    "    med['geometry'] = med['geometry'].simplify(tolerance=0.001, preserve_topology=True)\n",
    "    med.to_parquet(output_subdir / \"medium_detail.parquet\", engine='pyarrow', index=False)\n",
    "\n",
    "    # Low detail\n",
    "    low = gdf.copy()\n",
    "    low['geometry'] = low['geometry'].simplify(tolerance=0.005, preserve_topology=True)\n",
    "    low.to_parquet(output_subdir / \"low_detail.parquet\", engine='pyarrow', index=False)\n",
    "\n",
    "    print(f\"LOD created in: {output_subdir}\")\n",
    "    return output_subdir\n",
    "\n",
    "# Main workflow\n",
    "if __name__ == \"__main__\":\n",
    "    for csv_file in csv_dir.glob(\"*.csv\"):\n",
    "        print(f\"Processing {csv_file.name}...\")\n",
    "        # Preprocess and get parquet\n",
    "        parquet_path = preprocess_csv(csv_file)\n",
    "        # Create LOD folder per file\n",
    "        subdir = lod_dir / csv_file.stem\n",
    "        create_lod_files(parquet_path, subdir)\n",
    "\n",
    "    print(\"All files processed.\")\n"
   ],
   "id": "105dfad91a1b7a28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing distance-to-work.csv...\n",
      "Saved preprocessed: parquet\\distance-to-work.parquet\n",
      "LOD created in: lod_versions\\distance-to-work\n",
      "Processing emp-prop-filtered.csv...\n",
      "Saved preprocessed: parquet\\emp-prop-filtered.parquet\n",
      "LOD created in: lod_versions\\emp-prop-filtered\n",
      "Processing emp-prop.csv...\n",
      "Saved preprocessed: parquet\\emp-prop.parquet\n",
      "LOD created in: lod_versions\\emp-prop\n",
      "Processing emp-totals.csv...\n",
      "Saved preprocessed: parquet\\emp-totals.parquet\n",
      "LOD created in: lod_versions\\emp-totals\n",
      "Processing highest-quali.csv...\n",
      "Saved preprocessed: parquet\\highest-quali.parquet\n",
      "LOD created in: lod_versions\\highest-quali\n",
      "Processing msoa_attributes.csv...\n",
      "Saved preprocessed: parquet\\msoa_attributes.parquet\n",
      "LOD created in: lod_versions\\msoa_attributes\n",
      "Processing msoa_attributes_v2.csv...\n",
      "Saved preprocessed: parquet\\msoa_attributes_v2.parquet\n",
      "LOD created in: lod_versions\\msoa_attributes_v2\n",
      "Processing unemp.csv...\n",
      "Saved preprocessed: parquet\\unemp.parquet\n",
      "LOD created in: lod_versions\\unemp\n",
      "All files processed.\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
